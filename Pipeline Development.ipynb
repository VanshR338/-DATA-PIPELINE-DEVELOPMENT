{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de779927-7000-4848-92bc-4fab76cc88fe",
   "metadata": {},
   "source": [
    "IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "5dd8b7fa-1ffe-472e-9157-13b45f55c3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2bb961-05c6-460b-8cd8-10f775eb9eba",
   "metadata": {},
   "source": [
    "LOADING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "908f80b1-95fc-4b3c-b9d1-b6094a31db6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id     name   age  gender   salary           city\n",
      "0   1     John  28.0    Male  50000.0       New York\n",
      "1   2    Sarah  35.0  Female  60000.0  San Francisco\n",
      "2   3    David   NaN    Male  55000.0    Los Angeles\n",
      "3   4    Linda  30.0  Female      NaN        Chicago\n",
      "4   5  Michael  40.0    Male  75000.0            NaN\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"Employee_Data.csv\", encoding=\"ISO-8859-1\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "be97f193-e0be-4f0d-af19-83acd0d7bf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\"age\", \"salary\"]  \n",
    "categorical_features = [\"gender\", \"city\"]  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1228b40-06fa-4c91-8407-b7cdb595da89",
   "metadata": {},
   "source": [
    "ETL AUTOMATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c99e5a-f1c3-42b1-a963-aea7fa2e439c",
   "metadata": {},
   "source": [
    "EXTRACT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "32dde943-58a5-4ef6-b2f6-aa456c84657b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(file_path):\n",
    "     \"\"\"Extract data from a CSV file.\"\"\"\n",
    "    df = pd.read_csv(file_path, encoding=\"ISO-8859-1\")# Read the CSV file\n",
    "    print(\"Original Data:\")\n",
    "    print(df.head())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813a9b83-8e82-43a4-b544-92a82ab2cbed",
   "metadata": {},
   "source": [
    "TRANSFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "c3d21749-9720-4126-ad1d-7193206c5b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to transform the data (handling missing values, scaling, and encoding)\n",
    "def transform_data(df):\n",
    "    \n",
    "    \"\"\"Transform data: handle missing values, scale, and encode.\"\"\"\n",
    "    numeric_features = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    categorical_features = df.select_dtypes(include=['object']).columns.tolist()\n",
    "    \n",
    "    # Pipeline for numeric data: Impute missing values and scale the data\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    # Pipeline for categorical data: Impute missing values and encode categorical variable\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "    \n",
    "    # Apply transformations using ColumnTransformer\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ]\n",
    "    )\n",
    "    # Transform the dataset\n",
    "    processed_data = preprocessor.fit_transform(df)\n",
    "    processed_df = pd.DataFrame(processed_data)\n",
    "    print(\"Transformed Data:\")\n",
    "    print(processed_df.head())\n",
    "    return processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "957df739-9d35-491f-99ee-bf385e3ffb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df.to_csv(\"processed_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ea316b-baf7-4791-b936-ab573b3e237b",
   "metadata": {},
   "source": [
    "LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "558b2d50-feea-4544-a730-0b3ee3060e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load transformed data into a new CSV file\n",
    "def load_data(processed_df, output_file):\n",
    "    \"\"\"Load: Save transformed data to a new CSV file.\"\"\"\n",
    "    processed_df.to_csv(output_file, index=False)# Save the transformed data into a new CSV file\n",
    "    print(f\"Data successfully saved to {output_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "3343e291-d9e6-4a0b-8d88-e95c415c8958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete ETL pipeline function\n",
    "def etl_pipeline(input_file, output_file):\n",
    "    df = extract_data(input_file)# Step 1: Extract data\n",
    "    processed_df = transform_data(df)# Step 2: Transform data\n",
    "    load_data(processed_df, output_file) # Step 3: Load data into a new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "06e5d0e3-1c0e-4b0b-baf3-86e322dd5944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "   id     name   age  gender   salary           city\n",
      "0   1     John  28.0    Male  50000.0       New York\n",
      "1   2    Sarah  35.0  Female  60000.0  San Francisco\n",
      "2   3    David   NaN    Male  55000.0    Los Angeles\n",
      "3   4    Linda  30.0  Female      NaN        Chicago\n",
      "4   5  Michael  40.0    Male  75000.0            NaN\n",
      "Transformed Data:\n",
      "    0         1         2    3    4    5    6    7    8    9    10   11   12  \\\n",
      "0 -1.5 -0.690882 -0.832551  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   \n",
      "1 -1.0  0.847900  0.381586  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0   \n",
      "2 -0.5 -0.251230 -0.225483  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   \n",
      "3  0.0 -0.251230 -0.225483  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0   \n",
      "4  0.5  1.947030  2.202791  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  1.0   \n",
      "\n",
      "    13   14   15   16   17  \n",
      "0  0.0  0.0  1.0  0.0  0.0  \n",
      "1  0.0  0.0  0.0  1.0  0.0  \n",
      "2  0.0  1.0  0.0  0.0  0.0  \n",
      "3  0.0  0.0  0.0  0.0  0.0  \n",
      "4  0.0  0.0  0.0  0.0  0.0  \n",
      "Data successfully saved to Processed_Employee_Data.csv\n"
     ]
    }
   ],
   "source": [
    "# Example usage of the ETL pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    input_csv = \"Employee_Data.csv\" #Path to input CSV file (Update with actual file path)  \n",
    "    output_csv = \"Processed_Employee_Data.csv\" # Path to output CSV file\n",
    "    etl_pipeline(input_csv, output_csv)# Execute the ETL pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ba3ef3-3300-47d8-971b-6eb5c1281755",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
